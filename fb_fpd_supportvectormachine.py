# -*- coding: utf-8 -*-
"""FB_FPD_SupportVectorMachine.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nsLV4TpbJbH1MzK2APb6cmigwSed654Y

### **Importing Required Modules**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pickle
import pandas as pd
from sklearn.svm import SVC
from sklearn import preprocessing
import sexmachine.detector as gender
from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV
# %matplotlib inline

"""### **Function for reading dataset from csv files**"""

def read_datasets():
    """ Reads users profile from csv files """
    users = pd.read_csv(r'processed_data.csv')
    y=1337*[1] + 1481*[0]
    return users,y


"""### **Function for predicting gender**"""

def predict_sex(name):
    sex_predictor = gender.Detector(unknown_value=u"unknown",case_sensitive=False)
    first_name= name.str.split(' ').str.get(0)
    sex= first_name.apply(sex_predictor.get_gender)
    sex_dict={'female': -2, 'mostly_female': -1,'unknown':0,'mostly_male':1, 'male': 2}
    sex_code = sex.map(sex_dict).astype(int)
    return sex_code

"""### **Function for Feature extraction**"""

def extract_features(x):
    lang_list = list(enumerate(np.unique(x['lang'])))   
    lang_dict = { name : i for i, name in lang_list }             
    x.loc[:,'lang_code'] = x['lang'].map( lambda x: lang_dict[x]).astype(int)    
    x.loc[:,'sex_code']=predict_sex(x['name'])
    feature_columns_to_use = ['created_at','location','statuses_count','followers_count','favourites_count','friends_count','sex_code','lang_code']
    x=x.loc[:,feature_columns_to_use]
    return x

"""### **Reading Dataset**"""

print("reading datasets.....\n")
x,y=read_datasets()

"""### **Extracting Features**"""

print("extracting featues.....\n")
x=extract_features(x)

"""### **Spliting datasets into train and test dataset**"""

print "spliting datasets into train and test dataset...\n"
X_train,X_test,y_train,y_test = train_test_split(x, y, test_size=0.20, random_state=44)

"""### **Training Dataset**"""

print "training datasets.......\n"
# Scaling features
X_train=preprocessing.scale(X_train)
X_test=preprocessing.scale(X_test)
Cs = 10.0 ** np.arange(-2,3,.5)
gammas = 10.0 ** np.arange(-2,3,.5)
param = [{'gamma': gammas, 'C': Cs}]
cvk = StratifiedKFold(n_splits = 5)
classifier = SVC()
clf = GridSearchCV(classifier,param_grid=param,cv=cvk)
clf.fit(X_train,y_train)
print("The best classifier is: ",clf.best_estimator_)
clf.best_estimator_.fit(X_train,y_train)
# Predict class
y_pred = clf.best_estimator_.predict(X_test)

# Saving model to disk
pickle.dump(clf, open('support_vector_machine.pkl','wb'),protocol=2)
